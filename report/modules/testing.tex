\section{Testing}

Our unsorted numbers are generated in the following way:
\begin{lstlisting}
for i in {1..X}; do echo $RANDOM; done > test.dat
\end{lstlisting}
\begin{comment}
This line solves a syntax highlighting problem in vim caused by the isolated $ above.
\end{comment}
where x denotes the amount of numbers we want to have generated.
we've created 6 data-sets: $100$ $1.000$ $5.000$ $10.000$ $25.000$ $50.000$
furthermore, each data-set was generated 10 times in order to achieve 10 different test-candidates for each data-set.
Our test show that the program has passed all 6 data-set-size tests and completed all 60 tests as expected.\\
Correctness was asserted using the sort program, as described in the project description.\\
\\
Table \ref{table:data} contains the output of our test data. The times are gives in seconds, as given by the time program, and the mcips are given in mcips, rounded to three digits after the decimal point.\\
The table can be found as dataTable.txt.\\
\\
The data in the table show that the time used grows tremendously. Comparing the time for 5000 with the time for 50000 elements, which is a factor 10 of input size difference, but the difference in time used to sort is a factor of ~24.016. This factor should be higher, but we believe that the non-sorting tasks cause overhead that makes is more difficult to distinguish, as it contains linear time elements, making the scaling "flatter".\\
Furthermore, the mcips increases greatly with the input size as well, but the growth tapers off the highre the input gets. This is due to the fact that some of the time spent by the program isn't sorting, and when the input size grows, so does the percentage of time that is used on sorting, and hence the mcips performed by the proram in the sorting algorithm.\\
This leaves us to believe that for very large input sizes, it would be easier to pinpoint the scaling as quadratic, but running such large input sizes would be problematic, as a single run could potentially take several hours and would most likely be influenced by thread scheduling by the OS.

\begin{figure}[H]
\begin{tikzpicture}[baseline= (a).base]
\node[scale=.55] (a) at (0,0){
\begin{tikzcd}
test-candidate & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\
100\_time     & 0.003 & 0.003 & 0.004 & 0.002 & 0.002 & 0.002 & 0.003 & 0.003 & 0.003 & 0.003 \\
100\_mcips    & 1.797 & 1.859 & 1.526 & 2.788 & 2.770 & 2.745 & 1.781 & 1.806 & 1.801 & 1.742 \\
1.000\_time   & 0.017 & 0.018 & 0.018 & 0.018 & 0.028 & 0.109 & 0.017 & 0.006 & 0.017 & 0.020 \\
1.000\_mcips  & 29.533 & 28.185 & 29.065 & 28.563 & 18.368 & 4.745 & 28.619 & 82.672 & 28.751 & 25.177 \\
5.000\_time   & 0.062 &  0.053   &0.060   &0.054   &0.063   &0.062   &0.048  & 0.072 &  0.042  & 0.077 \\
5.000\_mcips  & 199.065 &236.321 &206.495 &233.048 &199.746 &204.553 &260.634 &175.149 &301.206 &162.070\\
10.000\_time  & 0.120   &0.127   &0.124   &0.118   &0.126   &0.114   &0.121   &0.124   &0.126   &0.120\\
10.000\_mcips & 425.313 &394.424 &404.921 &425.577 &398.966 &439.705 &412.804 &405.143 &394.039 &419.106\\
25.000\_time  & 0.420   &0.446   &0.452   &0.451   &0.445   &0.458   &0.443   &0.443   &0.457   &0.446\\
25.000\_mcips & 740.112 &702.718 &693.433 &694.715 &697.694 &688.212 &703.555 &702.573 &684.719 &706.682\\
50.000\_time  & 1.489   &1.469   &1.504   &1.490   &1.475   &1.464   &1.477   &1.450   &1.484   &1.468\\
50.000\_mcips & 838,971 &851.110 &832.697 &840.956 &846.079 &852.525 &848.984 &857.953 &840.672 &844.832
\end{tikzcd}
};
\end{tikzpicture}
\label{table:data}
\caption{Table of times and mcips}
\end{figure}
